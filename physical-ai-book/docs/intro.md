---
sidebar_position: 1
title: "Welcome to Physical AI & Humanoid Robotics"
description: "A comprehensive textbook for learning Physical AI, ROS 2, robot simulation, NVIDIA Isaac, and Vision-Language-Action models for humanoid robotics."
keywords: [physical ai, humanoid robotics, ros2, nvidia isaac, robotics course]
---

# Physical AI & Humanoid Robotics

Welcome to the **Physical AI & Humanoid Robotics** textbook — your comprehensive guide to building AI systems that operate in the real world.

## Why Physical AI?

The future of AI extends beyond digital spaces into the physical world. While language models and image generators have transformed how we work with data, the next frontier is **embodied intelligence** — AI systems that can see, move, manipulate, and interact with the physical environment.

Humanoid robots are poised to excel in our human-centered world because they share our physical form and can be trained with abundant data from interacting in human environments. This represents a massive shift from AI confined to screens to AI that walks among us.

## What You'll Learn

This course is organized into **4 modules** spanning **13 weeks**:

### Module 1: The Robotic Nervous System (ROS 2) — Weeks 1-5
Learn the middleware that powers modern robots. You'll master ROS 2 nodes, topics, services, and actions, build Python-based robot control packages, and describe humanoid robots using URDF.

### Module 2: The Digital Twin (Gazebo & Unity) — Weeks 6-7
Build virtual worlds for your robots. Simulate physics, gravity, and collisions in Gazebo. Add simulated sensors like LiDAR, depth cameras, and IMUs. Get introduced to Unity for high-fidelity visualization.

### Module 3: The AI-Robot Brain (NVIDIA Isaac) — Weeks 8-10
Harness NVIDIA's industrial robotics platform. Use Isaac Sim for photorealistic simulation, Isaac ROS for hardware-accelerated perception, and Nav2 for autonomous navigation — including bipedal locomotion planning.

### Module 4: Vision-Language-Action (VLA) — Weeks 11-13
Connect language models to robot actions. Build voice-to-action pipelines with Whisper, use LLMs for cognitive planning, and complete a capstone project integrating everything into an autonomous humanoid robot.

## Prerequisites

Before starting this course, you should have:

- **Python programming** experience (functions, classes, packages)
- **Basic Linux terminal** familiarity (navigating directories, running commands)
- **Fundamental AI/ML concepts** (helpful but not required)
- Access to a **Linux environment** (Ubuntu 22.04 recommended, WSL2 acceptable)

## How to Use This Book

1. **Read sequentially**: Chapters build on each other within each module
2. **Run the code**: Every code example is designed to be runnable — try them yourself
3. **Do the exercises**: Hands-on practice is where real learning happens
4. **Use the glossary**: Unfamiliar terms? Check the [Glossary](./appendices/glossary) in the appendices
5. **Check hardware requirements**: See the [Hardware Guide](./appendices/hardware-guide) for setup recommendations

## Course Assessments

Throughout the course, you will complete:

- **ROS 2 package development** project (Module 1)
- **Gazebo simulation** implementation (Module 2)
- **Isaac-based perception** pipeline (Module 3)
- **Capstone**: Simulated humanoid robot with conversational AI (Module 4)

---

Ready to begin? Start with [Introduction to Physical AI](./module-1-ros2/intro-physical-ai).
